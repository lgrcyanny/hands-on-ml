{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create your first Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "sess.run(f)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lifecycle of a Node Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "# x and w will be evaluated twice\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())  # 10\n",
    "    print(z.eval())  # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    [y_val, z_val] = sess.run([y, z])\n",
    "    print y_val\n",
    "    print z_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Linear Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /Users/lgrcyanny/scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(m, n) = housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_data_with_bias = np.c_[np.ones((m, 1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_with_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Linear Regression with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "(m, n) = housing.data.shape\n",
    "transformed_housing_data = StandardScaler().fit_transform(housing.data)\n",
    "housing_data_with_bias = np.c_[np.ones((m, 1)), transformed_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mse: 8.92024421692\n",
      "epoch: 100, mse: 8.92024421692\n",
      "epoch: 200, mse: 8.92024421692\n",
      "epoch: 300, mse: 8.92024421692\n",
      "epoch: 400, mse: 8.92024421692\n",
      "epoch: 500, mse: 8.92024421692\n",
      "epoch: 600, mse: 8.92024421692\n",
      "epoch: 700, mse: 8.92024421692\n",
      "epoch: 800, mse: 8.92024421692\n",
      "epoch: 900, mse: 8.92024421692\n",
      "[[ 0.63291645]\n",
      " [-0.438591  ]\n",
      " [-0.07727122]\n",
      " [-0.48363018]\n",
      " [-0.9213624 ]\n",
      " [ 0.28029251]\n",
      " [-0.47783971]\n",
      " [-0.82286477]\n",
      " [ 0.70768929]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.constant(housing_data_with_bias, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1), name=\"theta\")\n",
    "    y_predictions = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_predictions - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "    gradients = (2 / m) * tf.matmul(tf.transpose(X), error, name=\"gradients\") # must be 2 / m, not 2.0/m\n",
    "    training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            mse_val = sess.run(mse)\n",
    "            print(\"epoch: {}, mse: {}\".format(i, mse_val))\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mse: 7.51960229874\n",
      "epoch: 100, mse: 0.829821288586\n",
      "epoch: 200, mse: 0.676665604115\n",
      "epoch: 300, mse: 0.632684767246\n",
      "epoch: 400, mse: 0.602546274662\n",
      "epoch: 500, mse: 0.580851435661\n",
      "epoch: 600, mse: 0.565189063549\n",
      "epoch: 700, mse: 0.553876578808\n",
      "epoch: 800, mse: 0.545703113079\n",
      "epoch: 900, mse: 0.539797604084\n",
      "[[ 2.06855226]\n",
      " [ 0.78839767]\n",
      " [ 0.15214697]\n",
      " [-0.11072706]\n",
      " [ 0.14386316]\n",
      " [ 0.00818035]\n",
      " [-0.04127223]\n",
      " [-0.6951474 ]\n",
      " [-0.65728396]]\n"
     ]
    }
   ],
   "source": [
    "# With tensorflow GradientDescentOptimizer\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.constant(housing_data_with_bias, dtype=tf.float32, name=\"X\") # data has to been standard scaled\n",
    "    y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1), name=\"theta\")\n",
    "    y_predictions = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_predictions - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "    grad_loss = tf.Variable(tf.zeros(n + 1), name=\"grad_loss\")\n",
    "    gradients = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = gradients.minimize(mse)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            mse_val = sess.run(mse)\n",
    "            print(\"epoch: {}, mse: {}\".format(i, mse_val))\n",
    "        sess.run(training_op)\n",
    "    best_theta = sess.run(theta)\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feed data to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    B_val1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val2 = B.eval(feed_dict={A: [[1, 2, 3], [4, 5, 6]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mse: 5.91423034668\n",
      "epoch: 100, mse: 0.683947265148\n",
      "epoch: 200, mse: 0.58988904953\n",
      "epoch: 300, mse: 0.57032763958\n",
      "epoch: 400, mse: 0.557835936546\n",
      "epoch: 500, mse: 0.548844754696\n",
      "epoch: 600, mse: 0.54230594635\n",
      "epoch: 700, mse: 0.537540435791\n",
      "epoch: 800, mse: 0.534061789513\n",
      "epoch: 900, mse: 0.531518816948\n",
      "[[ 2.06855249]\n",
      " [ 0.827878  ]\n",
      " [ 0.14413993]\n",
      " [-0.21414192]\n",
      " [ 0.24205476]\n",
      " [ 0.00475607]\n",
      " [-0.04143694]\n",
      " [-0.71645463]\n",
      " [-0.6845808 ]]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression with placeholder\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1), name=\"theta\")\n",
    "    y_predictions = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_predictions - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "    grad_loss = tf.Variable(tf.zeros(n + 1), name=\"grad_loss\")\n",
    "    gradients = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = gradients.minimize(mse)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "x_batch = housing_data_with_bias\n",
    "y_batch = housing.target.reshape(-1, 1)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            mse_val = sess.run(mse, feed_dict={X: x_batch, y: y_batch})\n",
    "            print(\"epoch: {}, mse: {}\".format(i, mse_val))\n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch})\n",
    "    best_theta = sess.run(theta)\n",
    "print best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mse: 13.3487520218\n",
      "epoch: 100, mse: 1.02892303467\n",
      "epoch: 200, mse: 0.694108486176\n",
      "epoch: 300, mse: 0.640715181828\n",
      "epoch: 400, mse: 0.609049379826\n",
      "epoch: 500, mse: 0.586402952671\n",
      "epoch: 600, mse: 0.56992828846\n",
      "epoch: 700, mse: 0.557907581329\n",
      "epoch: 800, mse: 0.549122691154\n",
      "epoch: 900, mse: 0.542689681053\n",
      "[[ 2.06855249]\n",
      " [ 0.83025265]\n",
      " [ 0.15951233]\n",
      " [-0.19070593]\n",
      " [ 0.2103941 ]\n",
      " [ 0.01031574]\n",
      " [-0.04278753]\n",
      " [-0.602144  ]\n",
      " [-0.56919539]]\n",
      "/tmp/tensorflow/linear_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1), name=\"theta\")\n",
    "    y_predictions = tf.matmul(X, theta, name=\"predictions\")\n",
    "    error = y_predictions - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "    grad_loss = tf.Variable(tf.zeros(n + 1), name=\"grad_loss\")\n",
    "    gradients = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = gradients.minimize(mse)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "x_batch = housing_data_with_bias\n",
    "y_batch = housing.target.reshape(-1, 1)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            mse_val = sess.run(mse, feed_dict={X: x_batch, y: y_batch})\n",
    "            print(\"epoch: {}, mse: {}\".format(i, mse_val))\n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch})\n",
    "    best_theta = sess.run(theta)\n",
    "    save_path = saver.save(sess, \"/tmp/tensorflow/linear_model.ckpt\")\n",
    "print best_theta\n",
    "print save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tensorflow/linear_model.ckpt\n",
      "[[ 2.06855249]\n",
      " [ 0.83025265]\n",
      " [ 0.15951233]\n",
      " [-0.19070593]\n",
      " [ 0.2103941 ]\n",
      " [ 0.01031574]\n",
      " [-0.04278753]\n",
      " [-0.602144  ]\n",
      " [-0.56919539]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, save_path)\n",
    "    best_theta = sess.run(theta)\n",
    "    print best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"/tmp/tensorflow/{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, mse: 12.4321737289\n",
      "epoch: 100, mse: 0.681682825089\n",
      "epoch: 200, mse: 0.542516052723\n",
      "epoch: 300, mse: 0.536007881165\n",
      "epoch: 400, mse: 0.532868504524\n",
      "epoch: 500, mse: 0.530609071255\n",
      "epoch: 600, mse: 0.528959214687\n",
      "epoch: 700, mse: 0.527751922607\n",
      "epoch: 800, mse: 0.526866614819\n",
      "epoch: 900, mse: 0.526217103004\n",
      "/tmp/tensorflow/linear_model.ckpt\n",
      "[[  2.06855226e+00]\n",
      " [  8.32204282e-01]\n",
      " [  1.31969199e-01]\n",
      " [ -2.46595874e-01]\n",
      " [  2.79568762e-01]\n",
      " [  2.71917350e-04]\n",
      " [ -4.04995233e-02]\n",
      " [ -8.01107824e-01]\n",
      " [ -7.70911992e-01]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n + 1, 1], -1, 1), name=\"theta\")\n",
    "    y_predictions = tf.matmul(X, theta, name=\"predictions\")\n",
    "    with tf.name_scope(\"grad_loss\") as scope:\n",
    "        error = y_predictions - y\n",
    "        mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "        grad_loss = tf.Variable(tf.zeros(n + 1), name=\"grad_loss\")\n",
    "        gradients = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        training_op = gradients.minimize(mse)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    # add summary\n",
    "    mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "x_batch = housing_data_with_bias\n",
    "y_batch = housing.target.reshape(-1, 1)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            (mse_val, summary_str) = sess.run([mse, mse_summary], feed_dict={X: x_batch, y: y_batch})\n",
    "            print(\"epoch: {}, mse: {}\".format(i, mse_val))\n",
    "            file_writer.add_summary(summary_str, i)\n",
    "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch})\n",
    "    best_theta = sess.run(theta)\n",
    "    save_path = saver.save(sess, \"/tmp/tensorflow/linear_model.ckpt\")\n",
    "    print(save_path)\n",
    "    file_writer.close()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Variable Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
