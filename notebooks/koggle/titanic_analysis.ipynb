{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "train_data = pd.read_csv(\"/Users/lgrcyanny/Codecookies/machine-learning-workspace/hands-on-ml-wp/hands-on-ml/jupyter-notebooks/koggle/datasets/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/lgrcyanny/Codecookies/machine-learning-workspace/hands-on-ml-wp/hands-on-ml/jupyter-notebooks/koggle/datasets/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"PassengerId\", \"Survived\"], axis=1).copy()\n",
    "y_train = train_data.loc[:, \"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop([\"PassengerId\"], axis=1).copy()\n",
    "# y_test = test_data.loc([\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId   -0.005007\n",
       "Survived       1.000000\n",
       "Pclass        -0.338481\n",
       "Age           -0.077221\n",
       "SibSp         -0.035322\n",
       "Parch          0.081629\n",
       "Fare           0.257307\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(text_data, col_name):\n",
    "    pipeline = Pipeline([\n",
    "        (\"count_vec\", CountVectorizer()),\n",
    "        (\"tf_idf\", TfidfTransformer(norm='l2', use_idf=True, smooth_idf=False))])\n",
    "    encoded = pipeline.fit_transform(text_data)\n",
    "    encoded = encoded.toarray()\n",
    "    num_rows = encoded.shape[0]\n",
    "    encoded_df = pd.DataFrame(encoded, index=range(num_rows))\n",
    "    encoded_cols = encoded_df.columns\n",
    "    encoded_df.columns = [\"{0}_{1}\".format(col_name, col) for col in encoded_cols]\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1509)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_encoded = process_text(X_train[\"Name\"], \"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_encoded = process_text(X_train[\"Ticket\"], \"Ticket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. transform category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_cat(cat_cols, data):\n",
    "    cat_encoded = []\n",
    "    for col_name in cat_cols:\n",
    "        encoded_data = pd.get_dummies(data[col_name])\n",
    "        encoded_cols = encoded_data.columns\n",
    "        encoded_data.columns = [\"{0}_{1}\".format(col_name, col) for col in encoded_cols]\n",
    "        cat_encoded.append(encoded_data)\n",
    "    return cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"Sex\", \"Embarked\", \"Cabin\"]\n",
    "cat_encoded = process_cat(cat_cols, X_train)\n",
    "cat_encoded = pd.concat(cat_encoded, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cat = X_train.loc[:, [\"Pclass\", \"SibSp\", \"Parch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. process number columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_num(data, cols):\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "    num_transformed = num_pipeline.fit_transform(data)\n",
    "    num_rows = num_transformed.shape[0]\n",
    "    transformed_df = pd.DataFrame(num_transformed, index=range(num_rows))\n",
    "    transformed_df.columns = cols\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\", \"Fare\"]\n",
    "num_data = train_data.loc[:, num_cols]\n",
    "transformed_num_df = process_num(num_data, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed_train = pd.concat([transformed_num_df, original_cat, name_encoded, ticket_encoded, cat_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train and Evaluate data, Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "y_pred = cross_val_predict(rf_clf, X_processed_train, y_train, cv=3, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80808081,  0.83838384,  0.81481481])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = cross_val_score(rf_clf, X_processed_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84574558740506389"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_train, y_pred[:, 1])\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_eval(clf, X_train, y_train, method=\"predict_proba\"):\n",
    "    y_pred = cross_val_predict(clf, X_train, y_train, cv=3, method=method)\n",
    "    if len(y_pred.shape) > 1:\n",
    "        y_pred = y_pred[:, 1]\n",
    "    accuracies = cross_val_score(clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    print(\"accuracies\")\n",
    "    print accuracies\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(\"mean accuracy\", mean_accuracy)\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_train, y_pred)\n",
    "        print(\"auc\", auc_score)\n",
    "        f1 = f1_score(y_pred, y_train, average=\"macro\")\n",
    "        print(\"f1\", f1)\n",
    "        precision = precision_score(y_pred, y_train)\n",
    "        print(\"precision\", precision)\n",
    "        recall = recall_score(y_pred, y_train)\n",
    "        print(\"recall\", recall)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.8047138   0.83164983  0.83164983]\n",
      "('mean accuracy', 0.82267115600448937)\n",
      "('auc', 0.83977513607942145)\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "train_and_eval(rf_clf, X_processed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.7979798   0.82491582  0.81818182]\n",
      "('mean accuracy', 0.8136924803591471)\n",
      "('auc', 0.8680375802895216)\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "train_and_eval(lr_clf, X_processed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.79461279  0.81818182  0.82491582]\n",
      "('mean accuracy', 0.8125701459034792)\n",
      "('auc', 0.79663982360272267)\n",
      "('f1', 0.79968228539118602)\n",
      "('precision', 0.72807017543859653)\n",
      "('recall', 0.77089783281733748)\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier()\n",
    "train_and_eval(tree_clf, X_processed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.81144781  0.84175084  0.82828283]\n",
      "('mean accuracy', 0.8271604938271605)\n",
      "('auc', 0.86547044599963785)\n"
     ]
    }
   ],
   "source": [
    "gbdt_clf = GradientBoostingClassifier(max_depth=6)\n",
    "train_and_eval(gbdt_clf, X_processed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.81144781  0.47474747  0.74074074]\n",
      "('mean accuracy', 0.6756453423120089)\n",
      "('auc', 0.77010833093663122)\n",
      "('f1', 0.76311591634172282)\n",
      "('precision', 0.76608187134502925)\n",
      "('recall', 0.67875647668393779)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier()\n",
    "train_and_eval(sgd_clf, X_processed_train, y_train, method=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.73400673  0.76430976  0.54882155]\n",
      "('mean accuracy', 0.68237934904601572)\n",
      "('auc', 0.74729172658422016)\n",
      "('f1', 0.74094278245337275)\n",
      "('precision', 0.73684210526315785)\n",
      "('recall', 0.65454545454545454)\n"
     ]
    }
   ],
   "source": [
    "svm_clf = svm.SVC(kernel=\"polynomial\")\n",
    "train_and_eval(sgd_clf, X_processed_train, y_train, method=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best model is GBDT\n",
    "gbdt_clf.fit(X_processed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies\n",
      "[ 0.81818182  0.83501684  0.83838384]\n",
      "('mean accuracy', 0.83052749719416374)\n",
      "('auc', 0.8128654970760234)\n",
      "('f1', 0.81774081023049772)\n",
      "('precision', 0.73684210526315785)\n",
      "('recall', 0.805111821086262)\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost\n",
    "xgbt_clf = XGBClassifier(max_depth=8)\n",
    "train_and_eval(xgbt_clf, X_processed_train, y_train, method=\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Do prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1285)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(X_train):\n",
    "    name_encoded = process_text(X_train[\"Name\"], \"Name\")\n",
    "    ticket_encoded = process_text(X_train[\"Ticket\"], \"Ticket\")\n",
    "    cat_cols = [\"Sex\", \"Embarked\", \"Cabin\"]\n",
    "    cat_encoded = process_cat(cat_cols, X_train)\n",
    "    cat_encoded = pd.concat(cat_encoded, axis=1)\n",
    "    original_cat = X_train.loc[:, [\"Pclass\", \"SibSp\", \"Parch\"]]\n",
    "    num_cols = [\"Age\", \"Fare\"]\n",
    "    num_data = train_data.loc[:, num_cols]\n",
    "    transformed_num_df = process_num(num_data, num_cols)\n",
    "    X_processed_train = pd.concat([transformed_num_df, original_cat, name_encoded, ticket_encoded, cat_encoded], axis=1)\n",
    "    return X_processed_train\n",
    "X_processed_test = preprocess_data(X_test)\n",
    "X_processed_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = gbdt_clf.predict(X_processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
